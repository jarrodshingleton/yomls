library(reticulate)
os <- import("os")
os$listdir(".")
def add(x, y):
return x + y
py_run_string("x = 10")
# access the python main module via the 'py' object
py$x
data(iris)
ls
iris
install.packages("blogdown")
server_start()
blogdown::server_start()
?blogdown
??blogdown
library(blogdown)
blogdown::new_site()
blogdown::html_page()
blogdown::build_site()
blogdown::build_site()
158/200
4*80
13811/32
13811/320
library('pdftools')
install.packages("pdftools")
<<<<<<< HEAD
setwd("~/Documents/Army/DSC/EITaaS")
dir()
test1<-pdf_text('NoviSurvey_EITaaSAFC_20200630_7-1-2020.pdf')
library(pdftools)
test1<-pdf_text('NoviSurvey_EITaaSAFC_20200630_7-1-2020.pdf')
head(test1)
library(dplyr)
test1<-pdf_text('NoviSurvey_EITaaSAFC_20200630_7-1-2020.pdf')%>%strsplit(split="\n")
head(test1)
test2<-unlist(test1)
head(test2)
test2
setwd("~/Documents/YOMLS/content/post/pdfReading")
library(pdftools)
pdf1<-pdf_text('samplePDF.pdf')
head(pdf1)
str(pdf1)
pdf1<-strsplit(pdf1, split="\n")
str(pdf1)
head(pdf1)
knit_with_parameters('~/Documents/YOMLS/content/post/pdfReading/DataFromPDF.Rmd')
setwd("~/Documents/YOMLS/content/post/textStart")
pdf1<-pdf_text('samplePDF.pdf')
library(pdftools)
pdf1<-pdf_text('samplePDF.pdf')
head(pdf1)
pdf1<-strsplit(pdf1, split="\n")
pdf1
pdf1<-unlist(pdf1)
pdf1
str(pdf1)
library(tm)
corpus<-iconv(pdf1)
corpus<-Corpus(VectorSource(corpus))
corpus<-tm_map(corpus, tolower)
corpus<-tm_map(corpus, removePunctuation)
corpus<-tm_map(corpus, removeNumbers)
corpus<-tm_map(corpus, removeWords, stopwords('english'))  ##stopwords where are spanish!
cleanset<-tm_map(corpus, stripWhitespace)
tdm<-as.matrix(TermDocumentMatrix(cleanset))
tdm
w<-rowSums(tdm)
w<-sort(rowSums(tdm), decreasing=TRUE)
w2<-data.frame(names(w), w)
names(w2)<-c("word","freq")
w2$word <- factor(w2$word, levels = w2$word[order(w2$freq,decreasing=TRUE)])
head(w2)
set.seed(222)
wordcloud(words=w2$word, freq=w2$freq, max.words=50,
min.freq=5, colors=brewer.pal(8, 'Dark2'),
scale=c(7, 0.3),
rot.per=0.3)
library(wordcloud)
wordcloud(words=w2$word, freq=w2$freq, max.words=50,
min.freq=5, colors=brewer.pal(8, 'Dark2'),
scale=c(7, 0.3),
rot.per=0.3)
wordcloud(words=w2$word, freq=w2$freq, max.words=50,
min.freq=2, colors=brewer.pal(8, 'Dark2'),
scale=c(7, 0.3),
rot.per=0.3)
wordvect<-rep(w2$word, w2$freq)
wordvect<-as.character(wordvect)
s<-get_nrc_sentiment(wordvect, language="english")
library(syuzhet) #for sentiment analysis
library(ggplot2)
s<-get_nrc_sentiment(wordvect, language="english")
head(s)
test1<-as.data.frame(colSums(s))
names(test1)<-"Count"
test1$names<-rownames(test1)
test1$names<-as.factor(test1$names)
test1$names<-factor(test1$names, levels=c("anger","anticipation" ,"disgust"  ,    "fear"      ,   "joy"     ,     "sadness"  ,    "surprise",
"trust","negative"  ,   "positive" ))
g<-ggplot(test1)+geom_bar(aes(x=names, y=Count), stat="identity")+
theme_bw()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
xlab("")+
ylab("")
g
=======
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
>>>>>>> e69bb9f979c387e10b137e4716ca8370a38905b7
